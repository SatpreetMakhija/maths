\documentclass{report}
\usepackage{amsthm} % this is required for maths theorems
\usepackage{todonotes}
\usepackage[colorlinks=true, linkcolor=blue]{hyperref} % Enable hyperlinks

\begin{document}

\newcommand{\vectorv}{v = a_1v_1 + a_2v_2 + ... + a_nv_n}

\listoftodos


\chapter{Vector Spaces}

\chapter{Finite-Dimensional Vector Spaces}
\section{Span and Linear Independence}

Test case to create generic vector using \textit{vectorv} command: $\vectorv$

\section{Bases}

A \textit{basis} of $ V $ is a list of vectors in $V$ that is linearly independent and spans $V$. \\
How do we check if a given list of vectors is a basis or not?\\
One option is to check if they are linearly independent and span the space.But, we have a more beautiful solution. A criteria that when satisfied ensures that the given list of vectors is a basis.

\newtheorem{criteria-for-basis}{Criteria for basis}



\begin{criteria-for-basis}
	A list $ v_1, v_2, ..., v_n $ of vectors span $V$ iff every $v$ in $V$ can be written \textit{uniquely} in the form \\
	$ v = a_1v_1 + ... + a_nv_n$
\end{criteria-for-basis}

This is similar to the criteria of linear independence which is encoded by the criteria that a list of vectors are linearly independent \textit{iff} their sum equals zero only when all coefficients are zero themselves.

\textbf{How will we determine if given a list of $k$ vectors for a space with dimension $m$, and $k >> m$, which $m$ vectors in $k$ form a basis for $V$, if any? Is there an algorithm for it?}\\
Clearly, there are $C(k, m)$ options available. Given a particular combination, is there an algorithm to determine if they meet the criteria equation of linear independence. \todo{Algorithm to find basis given a list of vectors}\\

\newtheorem{subspace-and-another-sum-to-space}{Every subspace of$V$ is part of a direct sum equal to V}
\begin{subspace-and-another-sum-to-space}
Suppose $V$ is finite dimensional and $U$ is a subspace of $V$. Then \textbf{there exists} a subspace $W$ of $V$ such that $V = U + W$. 
\end{subspace-and-another-sum-to-space}


Because $V$ is finite dimensional, so is $U$. Let $u_1, u_2, ..., u_m$ be the basis for $U$. Clearly, this basis can be extended by adding $w_1, w_2, ..., w_k$ such that $u_1, u_2, ..., u_m, w_1, ..., w_k$ span $V$. 

Let $W=span(w_1,...,w_k)$. We need to show $V = U + W$ and $V = U \intersection W = {0}$.\\ 
For any $v \in V$, because $u_1,...,u_m,w_1,...w_k$ span V, there exists $a_1,...a_m,b_1,...,b_k$ such that $v = a_1u_1 + ... a_mu_m + b_1w_1 + ... + b_kw_k = u + w$. $\therefore V = U + W$.\\
Now, we need to show the intersection property.Let $v \in U \intersection W$. Then, there exists scalars $a_1,...a_m$ and $b_1,...,b_k$ such that \\
$v = a_1u_1 + ... + a_mu_m = b_1w_1 + ... + b_kw_k$ or $a_1u_1 + ... + a_mu_m + b_1w1 + b_kw_k = 0$. Since, all vectors are independent, $a_1 = ... = a_m = b_1 + ... b_k$. Thus, $v=0$. Note, we had taken any arbitrary $v$ part of the intersection\dots

Hence, proved. $\qed$


\section*{Exercises 2.B}
\subsection*{5}
Intuitively, there cannot exist such a basis because if there is no polynomial $p$ of degree 2, how can we represent $P_3(R)$. One way to solve this is take any 4 poynomials, assume they are independent, write their general, write their sum (the 4 polynomials) and we won't have a single term with degree 2. Therefore, there cannot exist such a basis. Hence proved.

\subsection*{6}
We need to show new list is also a basis. The criteria for basis is unique representation. As a helper method, we first show linear independence of the new list. That's easy. Assume non-independence and write independence criteria equation with assumption one of the coefficients is non-zero. Reshuffle all new terms such that they are written using original basis. This leads to contradiction as now a linear combination of original basis with at least one coefficient non-zero on the LHS and 0 on RHS. Since, all coefficients need to be 0, non-independence of the new list is false. Hence, independence shown.\\
Next, we need to show unique representation using the new new list. Assume two sets of coefficients lead to a common vector. Write the two representations with LHS = RHS. Because, we know the new list is independent, this leads to all corresponding coefficients in the two sets being equal. Hence, unique representation. Hence, proved. 

As a side note, any linear combination of the new list can be rewritten as a combination of the original basis and the original basis spans $V$. Hence, the new list also spans $V$. Another way to think of it is every $v$ can be written as a linear combination of the original basis and that representation can be written as a linear combination of the new list. That is the definition of spanning. For every $v$, there exists a representation using the list.


\section{Dimension}
The dimension of a vector space $V$ is defined as the length of its basis. Every basis for a given vector space has the same length which can be stated below. 

\subsection{Basis length does not depend on basis}

\paragraph{outline of proof}

There's a logical statment that will help us. When we say $x$ is less than and equal to $y$ and $y$ is less than or equal to $x$, i.e., $x \leq y$ and $y \leq x$, we get $x=y$. Example, take two numbers $2 \leq 4$and $4 \leq 2$, the only way other criteria is fullfilled is is $4$ changes to $2 $. 
\paragraph{proof} 

Let $B_1,B_2$ be two basis for $V$. $B_1$ is linearly independent and $B_2$ spans $V$. $\therefore$, $len(B_1) \leq len(B_2)$. Note, we are using the property that the length of the linearly independent list is less than or equal to the length of the spanning list. /todo{Prove this statement without looking at the book}. Similarly, we show $len(B_1) \leq len(B_2)$. Hence, $len(B_1) = len(B_2)$. 


\subsection{Changing field changes the dimension of a vector space}
Let's take $R_2$ as the vector space defined over $R$. The dimension is obviously $2$. But, if the same vector space $R_2$ is defined over field $C$, the dimension is 1. First of all, $c(x,y) \neq (cx,cy)$. That's not how we can multiply a complex number with a $v \in V$. Actually, the scalar multiplication is defined by the field not the vector space. So, when $R_2$ is defined over $R$, $c(x,y) = (cx,cy)$. When defined over $C$, $c(x,y) = (a+b\iota) (x + y\iota) = (ax-by) + (ay+bx)\iota$ and the we reinterpret it as an element of $R_2$, i.e., $(ax-by),(ay+bx)$. This reinterpretation is allowed because the scalar multiplication is defined as an operation $\lambda v$ such that the result is still in  $V$ and that this holds true $\forall \lambda \in F$, $F$ is the field and  $v \in V$.

\paragraph{show $(5,7),(4,3)$ is a basis of $F$.} 

Basis definition says list must span $F$ and it must be linearly independent. Let's use the independent criteria check. $a(5,7) + b(4,3) = 0$ iff $a = b = 0$. This can be solved by setting up a system of linear equations:
\[
5a + 4b = 0 and 7a + 3b = 0 
.\] 
\[
b = \frac{-5a}{4}
.\] 
\[
\therefore 7a + 3\frac{-5a}{4} = 0 
.\] 
\[
a = 0 
.\] 
\[
b = 0 
.\] 
Therefore, they are linearly independent. We know that the length of basis for $F_2$ is $2$. And here this independent list also has that length. So, we don't need to check whether it spans $F_2$ or not. We have another rule. Basis check needs two criteria, linear independence and spanning. If we know the list in question has the length equal to that of the $\dim V$, we only need to check one of the two criteria. 



















































\end{document}

